{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6578abc",
   "metadata": {},
   "source": [
    "Function to find root of this project. This is not required when using the code normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50b2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "root = Path.cwd()\n",
    "\n",
    "while not((root / 'requirements.txt').exists() and (root / 'README.md').exists()):\n",
    "    root = root.parent\n",
    "\n",
    "root = root / 'src'\n",
    "\n",
    "os.chdir(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22693c99",
   "metadata": {},
   "source": [
    "# Start of actual code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0744135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skopt.learning import GaussianProcessRegressor\n",
    "from skopt.learning.gaussian_process.kernels import Matern, WhiteKernel, RBF, RationalQuadratic\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ml_utils.design_eval.bayes_opt import suggest_next_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning) # related to reducing the minimum noise, which we wish to avoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d66936",
   "metadata": {},
   "source": [
    "# example of Bayesian Optimization in a 1D system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "X = np.array([[0.1], [0.3], [0.6], [0.8]])\n",
    "y = np.array([-0.5, -0.2, 0.4, 0.1])\n",
    "\n",
    "# fit the model\n",
    "kernel = Matern(length_scale=1.0, nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=5,\n",
    "    random_state=0)\n",
    "\n",
    "gp.fit(X, y)\n",
    "\n",
    "# define the candidate space\n",
    "X_candidates = np.linspace(0.1,0.9,100).reshape(-1, 1)\n",
    "\n",
    "# use Bayesian Optimization to recommend 3 experiments\n",
    "acq, i_suggested, x_suggested = suggest_next_experiment(X,\n",
    "                                                        y,\n",
    "                                                        X_candidates,\n",
    "                                                        goal='max',\n",
    "                                                        model_actual=gp,\n",
    "                                                        acq_func_name='EI',\n",
    "                                                        n_suggestions=3,\n",
    "                                                        kriging_believer='prediction',\n",
    "                                                        xi=0.1)\n",
    "\n",
    "# visualize the results\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X, y)\n",
    "\n",
    "y_pred, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "X_candidates_1d = X_candidates.flatten()\n",
    "ax.plot(X_candidates_1d, y_pred)\n",
    "ax.fill_between(X_candidates_1d, y_pred - y_std, y_pred + y_std, alpha=0.5)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(X_candidates_1d, acq[0], c='k')\n",
    "for x in x_suggested:\n",
    "    ax.axvline(x, c='k', ls=':')\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax2.set_ylabel('acq. func. value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8063681",
   "metadata": {},
   "source": [
    "# more complex example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7117eff5",
   "metadata": {},
   "source": [
    "## pretend that this is our exact system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d00b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_system(x):\n",
    "    return np.sin(x) - np.exp(-x**2) + np.log(x**2) + 1\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "X = np.linspace(-10, 10, 200)\n",
    "y = my_system(X)\n",
    "ax.plot(X, y)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52531736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with 4 evenly spaced points\n",
    "x_min_design, x_max_design, n_data = -10, 10, 4\n",
    "X = np.linspace(x_min_design, x_max_design, n_data).reshape(-1, 1)\n",
    "y = my_system(X).flatten()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X.flatten(), y)\n",
    "ax.set_title('Our understanding of the space with just 4 examples')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f068a8f",
   "metadata": {},
   "source": [
    "# use Bayes opt to find the global maximum\n",
    "## start with the basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "kernel = RationalQuadratic() + WhiteKernel(0.1)\n",
    "\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=100,\n",
    "    random_state=0)\n",
    "\n",
    "gp.fit(X, y)\n",
    "\n",
    "# define the candidate space\n",
    "X_candidates = np.linspace(x_min_design, x_max_design, 100).reshape(-1, 1)\n",
    "\n",
    "# use Bayesian Optimization to recommend 3 experiments\n",
    "acq, i_suggested, X_suggested = suggest_next_experiment(X,\n",
    "                                                        y,\n",
    "                                                        X_candidates,\n",
    "                                                        goal='max',\n",
    "                                                        model_actual=gp,\n",
    "                                                        acq_func_name='EI',\n",
    "                                                        n_suggestions=2,\n",
    "                                                        kriging_believer='prediction',\n",
    "                                                        xi=1)\n",
    "\n",
    "# visualize the results\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X, y)\n",
    "\n",
    "y_pred, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "X_candidates_1d = X_candidates.flatten()\n",
    "ax.plot(X_candidates_1d, y_pred)\n",
    "ax.fill_between(X_candidates_1d, y_pred - y_std, y_pred + y_std, alpha=0.5)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "for x in X_suggested:\n",
    "    ax.axvline(x, c='k', ls=':')\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax2.set_ylabel('acq. func. value')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340cc119",
   "metadata": {},
   "source": [
    "## update the model and try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bafcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([X, X_suggested])\n",
    "y = my_system(X).flatten()\n",
    "\n",
    "gp.fit(X, y)\n",
    "\n",
    "# use Bayesian Optimization to recommend 3 experiments\n",
    "acq, i_suggested, X_suggested = suggest_next_experiment(X,\n",
    "                                                        y,\n",
    "                                                        X_candidates,\n",
    "                                                        goal='max',\n",
    "                                                        model_actual=gp,\n",
    "                                                        acq_func_name='EI',\n",
    "                                                        n_suggestions=1,\n",
    "                                                        kriging_believer='prediction',\n",
    "                                                        xi=0.1)\n",
    "\n",
    "# visualize the results\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X, y)\n",
    "\n",
    "y_pred, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "X_candidates_1d = X_candidates.flatten()\n",
    "ax.plot(X_candidates_1d, y_pred)\n",
    "ax.fill_between(X_candidates_1d, y_pred - y_std, y_pred + y_std, alpha=0.5)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "for x in X_suggested:\n",
    "    ax.axvline(x, c='k', ls=':')\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax2.set_ylabel('acq. func. value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28244d18",
   "metadata": {},
   "source": [
    "## update the model and try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fcc798",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([X, X_suggested])\n",
    "y = my_system(X).flatten()\n",
    "\n",
    "gp.fit(X, y)\n",
    "\n",
    "# use Bayesian Optimization to recommend 3 experiments\n",
    "acq, i_suggested, X_suggested = suggest_next_experiment(X,\n",
    "                                                        y,\n",
    "                                                        X_candidates,\n",
    "                                                        goal='max',\n",
    "                                                        model_actual=gp,\n",
    "                                                        acq_func_name='EI',\n",
    "                                                        n_suggestions=1,\n",
    "                                                        kriging_believer='prediction',\n",
    "                                                        xi=0.1)\n",
    "\n",
    "# visualize the results\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X, y)\n",
    "\n",
    "y_pred, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "X_candidates_1d = X_candidates.flatten()\n",
    "ax.plot(X_candidates_1d, y_pred)\n",
    "ax.fill_between(X_candidates_1d, y_pred - y_std, y_pred + y_std, alpha=0.5)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "for x in X_suggested:\n",
    "    ax.axvline(x, c='k', ls=':')\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax2.set_ylabel('acq. func. value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa1194d",
   "metadata": {},
   "source": [
    "## update once more and compare with ground truth\n",
    "we see that we got a really good maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979b7e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([X, X_suggested])\n",
    "y = my_system(X).flatten()\n",
    "\n",
    "gp.fit(X, y)\n",
    "\n",
    "# visualize the results\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X, y)\n",
    "\n",
    "y_pred, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "X_candidates_1d = X_candidates.flatten()\n",
    "ax.plot(X_candidates_1d, y_pred)\n",
    "ax.fill_between(X_candidates_1d, y_pred - y_std, y_pred + y_std, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "\n",
    "X_truth = np.linspace(x_min_design, x_max_design, 200)\n",
    "y_truth = my_system(X_truth)\n",
    "ax.plot(X_truth, y_truth, c='k', ls=':')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "\n",
    "# save the final max from Bayes Opt\n",
    "i = np.argmax(y)\n",
    "bayes_opt_best_max = (X[i], y[i])\n",
    "ax.scatter(bayes_opt_best_max[0], bayes_opt_best_max[1], c='k', marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71894ce",
   "metadata": {},
   "source": [
    "# now, let's try to find the global minimum\n",
    "## reset the design, startign witht the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(x_min_design, x_max_design, n_data).reshape(-1, 1)\n",
    "y = my_system(X).flatten()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X.flatten(), y)\n",
    "ax.set_title('Our understanding of the space with just 4 examples')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6c11bc",
   "metadata": {},
   "source": [
    "## let's do the same, but now we minize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "kernel = RationalQuadratic() + WhiteKernel(0.1)\n",
    "\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=100,\n",
    "    random_state=0)\n",
    "\n",
    "gp.fit(X, y)\n",
    "\n",
    "# define the candidate space\n",
    "X_candidates = np.linspace(x_min_design, x_max_design, 100).reshape(-1, 1)\n",
    "\n",
    "# use Bayesian Optimization to recommend 3 experiments\n",
    "acq, i_suggested, X_suggested = suggest_next_experiment(X,\n",
    "                                                        y,\n",
    "                                                        X_candidates,\n",
    "                                                        goal='min', # CHANGED TO MIN\n",
    "                                                        model_actual=gp,\n",
    "                                                        acq_func_name='EI',\n",
    "                                                        n_suggestions=2,\n",
    "                                                        kriging_believer='prediction',\n",
    "                                                        xi=1)\n",
    "\n",
    "# visualize the results\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X, y)\n",
    "\n",
    "y_pred, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "X_candidates_1d = X_candidates.flatten()\n",
    "ax.plot(X_candidates_1d, y_pred)\n",
    "ax.fill_between(X_candidates_1d, y_pred - y_std, y_pred + y_std, alpha=0.5)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "for x in X_suggested:\n",
    "    ax.axvline(x, c='k', ls=':')\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax2.set_ylabel('acq. func. value')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bd28a",
   "metadata": {},
   "source": [
    "## let's repeat 3x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb27b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    X = np.vstack([X, X_suggested])\n",
    "    y = my_system(X).flatten()\n",
    "\n",
    "    gp.fit(X, y)\n",
    "\n",
    "    # use Bayesian Optimization to recommend 3 experiments\n",
    "    acq, i_suggested, X_suggested = suggest_next_experiment(X,\n",
    "                                                            y,\n",
    "                                                            X_candidates,\n",
    "                                                            goal='min',\n",
    "                                                            model_actual=gp,\n",
    "                                                            acq_func_name='EI',\n",
    "                                                            n_suggestions=1,\n",
    "                                                            kriging_believer='prediction',\n",
    "                                                            xi=0.1)\n",
    "\n",
    "    # visualize the results\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(X, y)\n",
    "\n",
    "    y_pred, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "    X_candidates_1d = X_candidates.flatten()\n",
    "    ax.plot(X_candidates_1d, y_pred)\n",
    "    ax.fill_between(X_candidates_1d, y_pred - y_std, y_pred + y_std, alpha=0.5)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    for x in X_suggested:\n",
    "        ax.axvline(x, c='k', ls=':')\n",
    "\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax2.set_ylabel('acq. func. value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8128b21",
   "metadata": {},
   "source": [
    "## let's see how good our model did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the results\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X, y)\n",
    "\n",
    "y_pred, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "X_candidates_1d = X_candidates.flatten()\n",
    "ax.plot(X_candidates_1d, y_pred)\n",
    "ax.fill_between(X_candidates_1d, y_pred - y_std, y_pred + y_std, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "\n",
    "X_truth = np.linspace(x_min_design, x_max_design, 200)\n",
    "y_truth = my_system(X_truth)\n",
    "ax.plot(X_truth, y_truth, c='k', ls=':')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "\n",
    "i = np.argmin(y)\n",
    "bayes_opt_best_min = (X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42457148",
   "metadata": {},
   "source": [
    "# but why not just take x points evenly spaced?\n",
    "\n",
    "So let's try to fit a model that took 8 evenly spaced points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43540b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the same number of points as Bayes opt above but evenly spaced\n",
    "X = np.linspace(x_min_design, x_max_design, X.shape[0]).reshape(-1, 1)\n",
    "y = my_system(X).flatten()\n",
    "\n",
    "# fit the model\n",
    "kernel = RationalQuadratic() + WhiteKernel(0.1)\n",
    "\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=100,\n",
    "    random_state=0)\n",
    "\n",
    "gp.fit(X, y)\n",
    "\n",
    "# visualize the results\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X, y)\n",
    "\n",
    "y_pred, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "X_candidates_1d = X_candidates.flatten()\n",
    "ax.plot(X_candidates_1d, y_pred)\n",
    "ax.fill_between(X_candidates_1d, y_pred - y_std, y_pred + y_std, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "\n",
    "X_truth = np.linspace(x_min_design, x_max_design, 200)\n",
    "y_truth = my_system(X_truth)\n",
    "ax.plot(X_truth, y_truth, c='k', ls=':')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "\n",
    "# plot the global min and global max of the evenly spread set\n",
    "i = np.argmin(y)\n",
    "ax.scatter(X[i], y[i], c='aqua', marker='*')\n",
    "i = np.argmax(y)\n",
    "ax.scatter(X[i], y[i], c='aqua', marker='*')\n",
    "\n",
    "# plot the min and max from Bayes Opt\n",
    "ax.scatter(bayes_opt_best_max[0], bayes_opt_best_max[1], c='k', marker='x')\n",
    "ax.scatter(bayes_opt_best_min[0], bayes_opt_best_min[1], c='k', marker='x')\n",
    "\n",
    "# plot the true min and max\n",
    "i = np.argmin(y_truth)\n",
    "ax.scatter(X_truth[i], y_truth[i], c='r', marker='+')\n",
    "i = np.argmax(y_truth)\n",
    "ax.scatter(X_truth[i], y_truth[i], c='r', marker='+')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aea818",
   "metadata": {},
   "source": [
    "We see that, at worst, Bayes Opt is approx. comparable to evenly spaced experimentation. At best, Bayes Opt is approx. better than evenly spaced experimentation. However, when it comes to getting a general idea of the entire space, evenly spaced experiments are definitely superior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
